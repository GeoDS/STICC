{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import esda\n",
    "import libpysal.weights as weights\n",
    "from esda.moran import Moran\n",
    "from shapely.geometry import Point, MultiPoint, LineString, Polygon, shape\n",
    "import json\n",
    "import pylab\n",
    "import libpysal\n",
    "import numpy as np\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics import f1_score\n",
    "from pyclustering.cluster.cure import cure\n",
    "from pyclustering.cluster.kmeans import kmeans\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation(lst):\n",
    "    if len(lst) == 0:\n",
    "        return []\n",
    "\n",
    "    if len(lst) == 1:\n",
    "        return [lst]\n",
    "\n",
    "    l = []\n",
    "    for i in range(len(lst)):\n",
    "        m = lst[i]\n",
    "        remLst = lst[:i] + lst[i+1:]\n",
    "        for p in permutation(remLst):\n",
    "            l.append([m] + p)       \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(df, permut):\n",
    "    def match_clus(x, permut):\n",
    "        if x == 0:\n",
    "            return int(permut[0])\n",
    "        elif x == 1:\n",
    "            return int(permut[1])\n",
    "        elif x == 2:\n",
    "            return int(permut[1])\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    df[\"group_match\"] = df[\"group\"].apply(lambda x: match_clus(x, permut))\n",
    "    return df, f1_score(df.group_match.values, df.clus_group_gt.values, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_f1_score(df):\n",
    "    max_f1 = 0\n",
    "    max_p = []\n",
    "    for p in permutation([1,3,4]):\n",
    "        df, f1 = get_f1_score(df, p)\n",
    "        if max_f1 < f1:\n",
    "            max_f1 = f1\n",
    "            max_p = p\n",
    "    print(\"f1_score \", max_f1, max_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_joint_statistic(nyc_data, w_voronoi):\n",
    "    matched_connects = 0\n",
    "    all_neighbors_connects = 0\n",
    "    for obj_id, neighbors in w_voronoi.neighbors.items():\n",
    "        obj_clus = nyc_data.iat[obj_id, -1]\n",
    "        for nei in neighbors:\n",
    "            nei_clus = nyc_data.iat[nei, -1]\n",
    "            all_neighbors_connects += 1\n",
    "            if obj_clus == nei_clus:\n",
    "                matched_connects += 1\n",
    "    return matched_connects / all_neighbors_connects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venueId</th>\n",
       "      <th>userId</th>\n",
       "      <th>gender</th>\n",
       "      <th>friend_num</th>\n",
       "      <th>follow_num</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>venueCateg</th>\n",
       "      <th>week</th>\n",
       "      <th>hour</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3fd66200f964a52000e71ee3</td>\n",
       "      <td>445</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.73385</td>\n",
       "      <td>-74.002998</td>\n",
       "      <td>Jazz Club</td>\n",
       "      <td>Sat</td>\n",
       "      <td>8</td>\n",
       "      <td>POINT (-74.00300 40.73385)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    venueId  userId gender  friend_num  follow_num  latitude  \\\n",
       "0  3fd66200f964a52000e71ee3     445   male         4.0        13.0  40.73385   \n",
       "\n",
       "   longitude venueCateg week  hour                    geometry  \n",
       "0 -74.002998  Jazz Club  Sat     8  POINT (-74.00300 40.73385)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_check_in = gpd.read_file('data/nyc_checkin.shp')\n",
    "nyc_check_in.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venueId</th>\n",
       "      <th>userId</th>\n",
       "      <th>gender</th>\n",
       "      <th>friend_num</th>\n",
       "      <th>follow_num</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>week</th>\n",
       "      <th>hour</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>venueCateg</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subway</th>\n",
       "      <td>10042</td>\n",
       "      <td>10042</td>\n",
       "      <td>10042</td>\n",
       "      <td>10042</td>\n",
       "      <td>10042</td>\n",
       "      <td>10042</td>\n",
       "      <td>10042</td>\n",
       "      <td>10042</td>\n",
       "      <td>10042</td>\n",
       "      <td>10042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            venueId  userId  gender  friend_num  follow_num  latitude  \\\n",
       "venueCateg                                                              \n",
       "Subway        10042   10042   10042       10042       10042     10042   \n",
       "\n",
       "            longitude   week   hour  geometry  \n",
       "venueCateg                                     \n",
       "Subway          10042  10042  10042     10042  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_check_in.groupby(\"venueCateg\").count().sort_values(\"venueId\").tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5909, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venueId</th>\n",
       "      <th>userId</th>\n",
       "      <th>gender</th>\n",
       "      <th>friend_num</th>\n",
       "      <th>follow_num</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>venueCateg</th>\n",
       "      <th>week</th>\n",
       "      <th>hour</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>3fd66200f964a5206fe71ee3</td>\n",
       "      <td>654</td>\n",
       "      <td>male</td>\n",
       "      <td>103.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>40.752901</td>\n",
       "      <td>-73.974176</td>\n",
       "      <td>Gym</td>\n",
       "      <td>Mon</td>\n",
       "      <td>17</td>\n",
       "      <td>POINT (-73.97418 40.75290)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       venueId  userId gender  friend_num  follow_num  \\\n",
       "1828  3fd66200f964a5206fe71ee3     654   male       103.0        46.0   \n",
       "\n",
       "       latitude  longitude venueCateg week  hour                    geometry  \n",
       "1828  40.752901 -73.974176        Gym  Mon    17  POINT (-73.97418 40.75290)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "venueCateg_list = [\"Gym\", \"Office\", \"Home (private)\"]\n",
    "venueId_list = pd.DataFrame(nyc_check_in.venueId.unique()).sample(frac=0.3).values.squeeze()\n",
    "nyc_check_sticc = nyc_check_in[(nyc_check_in.venueCateg.isin(venueCateg_list))&(nyc_check_in.venueId.isin(venueId_list))]\n",
    "print(nyc_check_sticc.shape)\n",
    "nyc_check_sticc.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kangyuhao/anaconda3/lib/python3.8/site-packages/geopandas/geodataframe.py:853: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n",
      "/home/kangyuhao/anaconda3/lib/python3.8/site-packages/geopandas/geodataframe.py:853: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "def return_week(x):\n",
    "    if x == \"Mon\":\n",
    "        return 1\n",
    "    elif x == \"Tue\":\n",
    "        return 2\n",
    "    elif x == \"Wed\":\n",
    "        return 3\n",
    "    elif x == \"Thu\":\n",
    "        return 4\n",
    "    elif x == \"Fri\":\n",
    "        return 5\n",
    "    elif x == \"Sat\":\n",
    "        return 6\n",
    "    elif x == \"Sun\":\n",
    "        return 7\n",
    "    \n",
    "def return_category(x):\n",
    "    if x == \"Gym\":\n",
    "        return 1\n",
    "    elif x == \"Coffee Shop\":\n",
    "        return 2\n",
    "    elif x == \"Office\":\n",
    "        return 3\n",
    "    elif x == \"Home (private)\":\n",
    "        return 4\n",
    "    elif x == \"Subway\":\n",
    "        return 5\n",
    "\n",
    "nyc_check_sticc[\"week_attr\"] = nyc_check_sticc[\"week\"].apply(lambda x: return_week(x))\n",
    "nyc_check_sticc[\"category\"] = nyc_check_sticc[\"venueCateg\"].apply(lambda x: return_category(x))\n",
    "nyc_check_sticc = nyc_check_sticc.reset_index().drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venueId</th>\n",
       "      <th>userId</th>\n",
       "      <th>gender</th>\n",
       "      <th>friend_num</th>\n",
       "      <th>follow_num</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>venueCateg</th>\n",
       "      <th>week</th>\n",
       "      <th>hour</th>\n",
       "      <th>geometry</th>\n",
       "      <th>week_attr</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3fd66200f964a5206fe71ee3</td>\n",
       "      <td>654</td>\n",
       "      <td>male</td>\n",
       "      <td>103.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>40.752901</td>\n",
       "      <td>-73.974176</td>\n",
       "      <td>Gym</td>\n",
       "      <td>Mon</td>\n",
       "      <td>17</td>\n",
       "      <td>POINT (-73.97418 40.75290)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    venueId  userId gender  friend_num  follow_num   latitude  \\\n",
       "0  3fd66200f964a5206fe71ee3     654   male       103.0        46.0  40.752901   \n",
       "\n",
       "   longitude venueCateg week  hour                    geometry  week_attr  \\\n",
       "0 -73.974176        Gym  Mon    17  POINT (-73.97418 40.75290)          1   \n",
       "\n",
       "   category  \n",
       "0         1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_check_sticc.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kangyuhao/anaconda3/lib/python3.8/site-packages/libpysal/weights/weights.py:172: UserWarning: The weights matrix is not fully connected: \n",
      " There are 140 disconnected components.\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "kd = libpysal.cg.KDTree(np.array(nyc_check_sticc[[\"latitude\", \"longitude\"]].values))\n",
    "wnn = libpysal.weights.KNN(kd, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_pt_0</th>\n",
       "      <th>n_pt_1</th>\n",
       "      <th>n_pt_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3556</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_pt_0  n_pt_1  n_pt_2\n",
       "0    3556       9      22"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_pt = pd.DataFrame().from_dict(wnn.neighbors, orient=\"index\")\n",
    "for i in range(nearest_pt.shape[1]):\n",
    "    nearest_pt = nearest_pt.rename({i:f\"n_pt_{i}\"}, axis=1)\n",
    "nearest_pt.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venueId</th>\n",
       "      <th>userId</th>\n",
       "      <th>gender</th>\n",
       "      <th>friend_num</th>\n",
       "      <th>follow_num</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>venueCateg</th>\n",
       "      <th>week</th>\n",
       "      <th>hour</th>\n",
       "      <th>geometry</th>\n",
       "      <th>week_attr</th>\n",
       "      <th>category</th>\n",
       "      <th>n_pt_0</th>\n",
       "      <th>n_pt_1</th>\n",
       "      <th>n_pt_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3fd66200f964a5206fe71ee3</td>\n",
       "      <td>654</td>\n",
       "      <td>male</td>\n",
       "      <td>103.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>40.752901</td>\n",
       "      <td>-73.974176</td>\n",
       "      <td>Gym</td>\n",
       "      <td>Mon</td>\n",
       "      <td>17</td>\n",
       "      <td>POINT (-73.97418 40.75290)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3556</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    venueId  userId gender  friend_num  follow_num   latitude  \\\n",
       "0  3fd66200f964a5206fe71ee3     654   male       103.0        46.0  40.752901   \n",
       "\n",
       "   longitude venueCateg week  hour                    geometry  week_attr  \\\n",
       "0 -73.974176        Gym  Mon    17  POINT (-73.97418 40.75290)          1   \n",
       "\n",
       "   category  n_pt_0  n_pt_1  n_pt_2  \n",
       "0         1    3556       9      22  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_check_sticc = nyc_check_sticc.join(nearest_pt)\n",
    "nyc_check_sticc.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_check_sticc[[\"week_attr\", \"hour\", \"n_pt_0\", \"n_pt_1\", \n",
    "                 \"n_pt_2\"]].to_csv(r'nyc_checkin3.txt', header=None, index=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_voronoi = weights.Voronoi.from_dataframe(nyc_check_sticc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STICC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam_sparse 0.1\n",
      "switch_penalty 5.0\n",
      "num_cluster 3\n",
      "num stacked 4\n",
      "completed getting the data\n",
      "2 (5909, 2) (5909, 3)\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 0\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 3087\n",
      "length of the cluster  1 ------> 1475\n",
      "length of the cluster  2 ------> 1347\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 3196\n",
      "length of cluster # 1 --------> 1611\n",
      "length of cluster # 2 --------> 1102\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 1\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 3196\n",
      "length of the cluster  1 ------> 1611\n",
      "length of the cluster  2 ------> 1102\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 3012\n",
      "length of cluster # 1 --------> 1478\n",
      "length of cluster # 2 --------> 1419\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 2\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 3012\n",
      "length of the cluster  1 ------> 1478\n",
      "length of the cluster  2 ------> 1419\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 2800\n",
      "length of cluster # 1 --------> 1490\n",
      "length of cluster # 2 --------> 1619\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 3\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 2800\n",
      "length of the cluster  1 ------> 1490\n",
      "length of the cluster  2 ------> 1619\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 2696\n",
      "length of cluster # 1 --------> 1554\n",
      "length of cluster # 2 --------> 1659\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 4\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 2696\n",
      "length of the cluster  1 ------> 1554\n",
      "length of the cluster  2 ------> 1659\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 2644\n",
      "length of cluster # 1 --------> 1606\n",
      "length of cluster # 2 --------> 1659\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 5\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 2644\n",
      "length of the cluster  1 ------> 1606\n",
      "length of the cluster  2 ------> 1659\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 2633\n",
      "length of cluster # 1 --------> 1614\n",
      "length of cluster # 2 --------> 1662\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 6\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 2633\n",
      "length of the cluster  1 ------> 1614\n",
      "length of the cluster  2 ------> 1662\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 2625\n",
      "length of cluster # 1 --------> 1636\n",
      "length of cluster # 2 --------> 1648\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 7\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 2625\n",
      "length of the cluster  1 ------> 1636\n",
      "length of the cluster  2 ------> 1648\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 2623\n",
      "length of cluster # 1 --------> 1640\n",
      "length of cluster # 2 --------> 1646\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 8\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 2623\n",
      "length of the cluster  1 ------> 1640\n",
      "length of the cluster  2 ------> 1646\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 2623\n",
      "length of cluster # 1 --------> 1640\n",
      "length of cluster # 2 --------> 1646\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 9\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 2623\n",
      "length of the cluster  1 ------> 1640\n",
      "length of the cluster  2 ------> 1646\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 2623\n",
      "length of cluster # 1 --------> 1638\n",
      "length of cluster # 2 --------> 1648\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 10\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 2623\n",
      "length of the cluster  1 ------> 1638\n",
      "length of the cluster  2 ------> 1648\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 2623\n",
      "length of cluster # 1 --------> 1647\n",
      "length of cluster # 2 --------> 1639\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 11\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 2623\n",
      "length of the cluster  1 ------> 1647\n",
      "length of the cluster  2 ------> 1639\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 2623\n",
      "length of cluster # 1 --------> 1646\n",
      "length of cluster # 2 --------> 1640\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 12\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 2623\n",
      "length of the cluster  1 ------> 1646\n",
      "length of the cluster  2 ------> 1640\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 2623\n",
      "length of cluster # 1 --------> 1644\n",
      "length of cluster # 2 --------> 1642\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 13\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 2623\n",
      "length of the cluster  1 ------> 1644\n",
      "length of the cluster  2 ------> 1642\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 2623\n",
      "length of cluster # 1 --------> 1637\n",
      "length of cluster # 2 --------> 1649\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 14\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 2623\n",
      "length of the cluster  1 ------> 1637\n",
      "length of the cluster  2 ------> 1649\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 2623\n",
      "length of cluster # 1 --------> 1641\n",
      "length of cluster # 2 --------> 1645\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 15\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 2623\n",
      "length of the cluster  1 ------> 1641\n",
      "length of the cluster  2 ------> 1645\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 2623\n",
      "length of cluster # 1 --------> 1644\n",
      "length of cluster # 2 --------> 1642\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 16\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 2623\n",
      "length of the cluster  1 ------> 1644\n",
      "length of the cluster  2 ------> 1642\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 2623\n",
      "length of cluster # 1 --------> 1643\n",
      "length of cluster # 2 --------> 1643\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 17\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 2623\n",
      "length of the cluster  1 ------> 1643\n",
      "length of the cluster  2 ------> 1643\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 2623\n",
      "length of cluster # 1 --------> 1646\n",
      "length of cluster # 2 --------> 1640\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 18\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 2623\n",
      "length of the cluster  1 ------> 1646\n",
      "length of the cluster  2 ------> 1640\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 2622\n",
      "length of cluster # 1 --------> 1639\n",
      "length of cluster # 2 --------> 1648\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ITERATION ### 19\n",
      "OPTIMIZATION for Cluster # 0 DONE!!!\n",
      "OPTIMIZATION for Cluster # 1 DONE!!!\n",
      "OPTIMIZATION for Cluster # 2 DONE!!!\n",
      "length of the cluster  0 ------> 2622\n",
      "length of the cluster  1 ------> 1639\n",
      "length of the cluster  2 ------> 1648\n",
      "UPDATED THE OLD COVARIANCE\n",
      "beginning the smoothening ALGORITHM\n",
      "length of cluster # 0 --------> 2622\n",
      "length of cluster # 1 --------> 1643\n",
      "length of cluster # 2 --------> 1644\n",
      "Done writing the figure\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TRAINING F1 score: -1 -1 -1\n",
      "[1.0000 1.0000 1.0000 ... 0.0000 0.0000 0.0000]\n"
     ]
    }
   ],
   "source": [
    "!python TICC_main.py --fname=nyc_checkin3.txt --oname=result_nyc_checkin3.txt --attr_idx_start=1 \\\n",
    "--attr_idx_end=2 --spatial_idx_start=3 --spatial_idx_end=5 \\\n",
    "--spatial_radius 4 --number_of_clusters 3 --lambda_parameter 10e-2 --beta 5 --maxIters 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted rand score 0.299048156707623\n",
      "Spatial contiguity:  0.7245619074978454\n",
      "f1_score  0.5239363875462164 [3, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "group = pd.read_table('result_nyc_checkin3.txt', names=[\"group\"])\n",
    "result_nyc_check_sticc = nyc_check_sticc.join(group)\n",
    "result_nyc_check_sticc = result_nyc_check_sticc.rename({\"category\": \"clus_group_gt\"}, axis=1)\n",
    "print(\"Adjusted rand score\", adjusted_rand_score(result_nyc_check_sticc[\"group\"].values, \n",
    "                                                 result_nyc_check_sticc.clus_group_gt.values))\n",
    "sp_contiguity = cal_joint_statistic(result_nyc_check_sticc, w_voronoi)\n",
    "print(\"Spatial contiguity: \", sp_contiguity)\n",
    "get_max_f1_score(result_nyc_check_sticc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pycluster_result(ground_truth, cluster_method):\n",
    "#     data = ground_truth[[\"week_attr\", \"hour\"]].values # For K-Means\n",
    "    data = ground_truth[[\"week_attr\", \"hour\", \"latitude\", \"longitude\"]].values # For Sp K-Means\n",
    "\n",
    "    if cluster_method == kmeans:\n",
    "        initial_centers = kmeans_plusplus_initializer(data.tolist(), 2).initialize()\n",
    "        instance = cluster_method(data.tolist(), initial_centers)\n",
    "    elif cluster_method == cure:\n",
    "        print(\"cure\")\n",
    "        instance = cure(data, 3)\n",
    "    else:\n",
    "        instance = cluster_method(data.tolist(), 2)\n",
    "\n",
    "    instance.process()\n",
    "    clusters = instance.get_clusters()\n",
    "    \n",
    "    clusters_result = []\n",
    "    for i, clus in enumerate(clusters):\n",
    "        for data in clus:\n",
    "            clusters_result.append([data, i])\n",
    "    clusters_result_df = pd.DataFrame(clusters_result, columns=[\"pt\", \"group\"]).sort_values(\"pt\").set_index(\"pt\")\n",
    "    return clusters_result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted rand score 0.06540493878619441\n",
      "Spatial contiguity:  0.6700948003447286\n",
      "f1_score  0.38086125317189695 [3, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "group = get_pycluster_result(nyc_check_sticc, kmeans)\n",
    "result_nyc_check_sticc = nyc_check_sticc.join(group)\n",
    "result_nyc_check_sticc = result_nyc_check_sticc.rename({\"category\": \"clus_group_gt\"}, axis=1)\n",
    "print(\"Adjusted rand score\", adjusted_rand_score(result_nyc_check_sticc[\"group\"].values, \n",
    "                                                 result_nyc_check_sticc.clus_group_gt.values))\n",
    "sp_contiguity = cal_joint_statistic(result_nyc_check_sticc, w_voronoi)\n",
    "print(\"Spatial contiguity: \", sp_contiguity)\n",
    "get_max_f1_score(result_nyc_check_sticc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sp K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted rand score 0.06540493878619441\n",
      "Spatial contiguity:  0.6700948003447286\n",
      "f1_score  0.38086125317189695 [3, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "group = get_pycluster_result(nyc_check_sticc, kmeans)\n",
    "result_nyc_check_sticc = nyc_check_sticc.join(group)\n",
    "result_nyc_check_sticc = result_nyc_check_sticc.rename({\"category\": \"clus_group_gt\"}, axis=1)\n",
    "print(\"Adjusted rand score\", adjusted_rand_score(result_nyc_check_sticc[\"group\"].values, \n",
    "                                                 result_nyc_check_sticc.clus_group_gt.values))\n",
    "sp_contiguity = cal_joint_statistic(result_nyc_check_sticc, w_voronoi)\n",
    "print(\"Spatial contiguity: \", sp_contiguity)\n",
    "get_max_f1_score(result_nyc_check_sticc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cure\n",
      "Adjusted rand score 0.0729293684699148\n",
      "Spatial contiguity:  0.6272335535765584\n",
      "f1_score  0.4208030109481018 [3, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "group = get_pycluster_result(nyc_check_sticc, cure)\n",
    "result_nyc_check_sticc = nyc_check_sticc.join(group)\n",
    "result_nyc_check_sticc = result_nyc_check_sticc.rename({\"category\": \"clus_group_gt\"}, axis=1)\n",
    "print(\"Adjusted rand score\", adjusted_rand_score(result_nyc_check_sticc[\"group\"].values, \n",
    "                                                 result_nyc_check_sticc.clus_group_gt.values))\n",
    "sp_contiguity = cal_joint_statistic(result_nyc_check_sticc, w_voronoi)\n",
    "print(\"Spatial contiguity: \", sp_contiguity)\n",
    "get_max_f1_score(result_nyc_check_sticc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venueId</th>\n",
       "      <th>userId</th>\n",
       "      <th>gender</th>\n",
       "      <th>friend_num</th>\n",
       "      <th>follow_num</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>venueCateg</th>\n",
       "      <th>week</th>\n",
       "      <th>hour</th>\n",
       "      <th>geometry</th>\n",
       "      <th>week_attr</th>\n",
       "      <th>category</th>\n",
       "      <th>n_pt_0</th>\n",
       "      <th>n_pt_1</th>\n",
       "      <th>n_pt_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3fd66200f964a5206fe71ee3</td>\n",
       "      <td>654</td>\n",
       "      <td>male</td>\n",
       "      <td>103.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>40.752901</td>\n",
       "      <td>-73.974176</td>\n",
       "      <td>Gym</td>\n",
       "      <td>Mon</td>\n",
       "      <td>17</td>\n",
       "      <td>POINT (-73.97418 40.75290)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3556</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    venueId  userId gender  friend_num  follow_num   latitude  \\\n",
       "0  3fd66200f964a5206fe71ee3     654   male       103.0        46.0  40.752901   \n",
       "\n",
       "   longitude venueCateg week  hour                    geometry  week_attr  \\\n",
       "0 -73.974176        Gym  Mon    17  POINT (-73.97418 40.75290)          1   \n",
       "\n",
       "   category  n_pt_0  n_pt_1  n_pt_2  \n",
       "0         1    3556       9      22  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_data = nyc_check_sticc.copy()\n",
    "gmm_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gmm_data[['hour', 'week_attr']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group\n",
       "0      1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm = GaussianMixture(n_components=3).fit(X)\n",
    "gmm = pd.DataFrame(gm.predict(X), columns=[\"group\"])\n",
    "gmm.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted rand score 0.09072443404391904\n",
      "Spatial contiguity:  0.6405630565929331\n",
      "f1_score  0.4349576813996136 [3, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "result_nyc_check_sticc = nyc_check_sticc.join(gmm)\n",
    "result_nyc_check_sticc = result_nyc_check_sticc.rename({\"category\": \"clus_group_gt\"}, axis=1)\n",
    "print(\"Adjusted rand score\", adjusted_rand_score(result_nyc_check_sticc[\"group\"].values, \n",
    "                                                 result_nyc_check_sticc.clus_group_gt.values))\n",
    "sp_contiguity = cal_joint_statistic(result_nyc_check_sticc, w_voronoi)\n",
    "print(\"Spatial contiguity: \", sp_contiguity)\n",
    "get_max_f1_score(result_nyc_check_sticc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
